{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3131ebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ff8b1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "# Scalar\n",
    "x = torch.tensor(5)\n",
    "print(x)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95e408b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Vector\n",
    "v = torch.tensor([1, 2, 3])\n",
    "print(v) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d6644e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix\n",
    "m = torch.tensor([[1, 2], [3, 4]])\n",
    "print(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf2492a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.])\n",
      "tensor([ 4., 10., 18.])\n",
      "tensor(32.)\n",
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1.0, 2.0, 3.0])\n",
    "b = torch.tensor([4.0, 5.0, 6.0])\n",
    "\n",
    "print(a + b)    # element-wise add\n",
    "print(a * b)    # element-wise multiply\n",
    "print(torch.dot(a, b))   # dot product\n",
    "print(a.mean()) # mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def2ab78",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Check if GPU is available\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# print(torch.cuda.is_available())\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Move tensor to GPU\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(x)\n",
      "File \u001b[0;32m~/Documents/Learning/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py:412\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    411\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 412\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    416\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "# print(torch.cuda.is_available())\n",
    "\n",
    "# Move tensor to GPU\n",
    "# x = torch.tensor([1, 2, 3], device=\"cuda\")\n",
    "# print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29ca8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)  # “Track all operations on this tensor because I’ll need gradients w.r.t. it later.”\n",
    "\n",
    "y = x**2 + 3*x + 5   # function\n",
    "\n",
    "y.backward()         # compute dy/dx\n",
    "print(x.grad)        # prints tensor(7.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf5511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbaad1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple model: input -> hidden -> output\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(1, 10),   # 1 input → 10 hidden neurons\n",
    "    nn.ReLU(),          # activation\n",
    "    nn.Linear(10, 1)    # 10 → 1 output\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4344e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c54a30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.571223482547794e-10\n",
      "10 4.780531526193954e-11\n",
      "20 4.604316927725449e-12\n",
      "30 5.115907697472721e-13\n",
      "40 5.115907697472721e-13\n",
      "50 5.115907697472721e-13\n",
      "60 5.115907697472721e-13\n",
      "70 5.115907697472721e-13\n",
      "80 2.2737367544323206e-13\n",
      "90 2.2737367544323206e-13\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    # Forward pass\n",
    "    y_pred = model(torch.tensor([[1.0]]))  # example input\n",
    "\n",
    "    # Compute loss\n",
    "    y_true = torch.tensor([[2.0]])         # example target\n",
    "    loss = loss_fn(y_pred, y_true)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(epoch, loss.item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
